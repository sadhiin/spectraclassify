<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Webcam-Inference</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #7350d1;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        .container {
            text-align: center;
        }

        button {
            padding: 10px 20px;
            background-color: #007BFF;
            color: white;
            border: none;
            border-radius: 4px;
            margin: 10px;
            cursor: pointer;
        }

        button:hover {
            background-color: #0056b3;
        }

        .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
        }

        video,
        img {
            margin: 10px;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Webcam-Inference</h1>
        <div class="video-container">
            <video id="liveVideo" width="640" height="480" autoplay></video>
            <img id="processedImg" width="640" height="480" style="display:none;">
        </div>
        <br>

        <button onclick="startCamera()">Start Webcam</button>
        <button onclick="stopCamera()">Stop Webcam</button>
        <br>
        <a href="{{url_for('home')}}">
            <button class="btn btn-primary">Home</button></a>
        <a href="{{ url_for('prediction') }}">
            <button class="btn btn-primary">Upload and Predict</button></a>
    </div>

    <script>
        let videoStream;
        let predictionInterval;

        async function startCamera() {
            videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
            let video = document.getElementById('liveVideo');
            video.srcObject = videoStream;
            video.play();

            predictionInterval = setInterval(async () => {
                const canvas = document.createElement('canvas');
                canvas.width = video.width;
                canvas.height = video.height;
                canvas.getContext('2d').drawImage(video, 0, 0, video.width, video.height);
                let imageBase64 = canvas.toDataURL('image/jpeg');
                fetch('/analyze', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/x-www-form-urlencoded',
                    },
                    body: `imageBase64=${encodeURIComponent(imageBase64)}`
                })
                    .then(response => response.json())
                    .then(data => {
                        console.log("Prediction: ", data.predictions)

                        let processedImg = document.getElementById('processedImg');
                        processedImg.src = "data:image/jpeg;base64," + data.img_base64;
                        processedImg.style.display = "block";
                    })
                    .catch(error => console.error('Error:', error));
            }, 100); // Running the prediction every 100 milliseconds
        }

        function stopCamera() {
            if (videoStream) {
                clearInterval(predictionInterval);
                videoStream.getTracks().forEach(track => track.stop());
                let processedImg = document.getElementById('processedImg');
                processedImg.style.display = "none";
            }
        }
    </script>
</body>

</html>